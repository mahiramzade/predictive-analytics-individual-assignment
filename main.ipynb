{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Predictive Analytics - Individual Assignment\n",
        "\n",
        "Data wrangling and analysis of King County property sales and Seattle crime data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pandas in ./.venv/lib/python3.12/site-packages (3.0.1)\n",
            "Requirement already satisfied: geopandas in ./.venv/lib/python3.12/site-packages (1.1.2)\n",
            "Collecting scipy\n",
            "  Downloading scipy-1.17.1-cp312-cp312-macosx_14_0_arm64.whl.metadata (62 kB)\n",
            "Requirement already satisfied: numpy>=1.26.0 in ./.venv/lib/python3.12/site-packages (from pandas) (2.4.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in ./.venv/lib/python3.12/site-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pyogrio>=0.7.2 in ./.venv/lib/python3.12/site-packages (from geopandas) (0.12.1)\n",
            "Requirement already satisfied: packaging in ./.venv/lib/python3.12/site-packages (from geopandas) (26.0)\n",
            "Requirement already satisfied: pyproj>=3.5.0 in ./.venv/lib/python3.12/site-packages (from geopandas) (3.7.2)\n",
            "Requirement already satisfied: shapely>=2.0.0 in ./.venv/lib/python3.12/site-packages (from geopandas) (2.1.2)\n",
            "Requirement already satisfied: certifi in ./.venv/lib/python3.12/site-packages (from pyogrio>=0.7.2->geopandas) (2026.2.25)\n",
            "Requirement already satisfied: six>=1.5 in ./.venv/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Downloading scipy-1.17.1-cp312-cp312-macosx_14_0_arm64.whl (20.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m20.3/20.3 MB\u001b[0m \u001b[31m41.5 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: scipy\n",
            "Successfully installed scipy-1.17.1\n"
          ]
        }
      ],
      "source": [
        "!pip install pandas geopandas scipy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Unique Years in Each Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "kingco_sales.csv (sales_df)\n",
            "Unique years (sale_date): [1999, 2000, 2001, 2002, 2003, 2004, 2005, 2006, 2007, 2008, 2009, 2010, 2011, 2012, 2013, 2014, 2015, 2016, 2017, 2018, 2019, 2020, 2021, 2022, 2023, 2024, 2025]\n",
            "Year range: 1999 - 2025\n",
            "\n",
            "Records per year:\n",
            "year\n",
            "1999    24392\n",
            "2000    22738\n",
            "2001    21932\n",
            "2002    23289\n",
            "2003    28080\n",
            "2004    31419\n",
            "2005    32502\n",
            "2006    29794\n",
            "2007    23228\n",
            "2008    14260\n",
            "2009    12974\n",
            "2010    13730\n",
            "2011    12717\n",
            "2012    16877\n",
            "2013    21603\n",
            "2014    22021\n",
            "2015    25050\n",
            "2016    26899\n",
            "2017    27079\n",
            "2018    23957\n",
            "2019    24282\n",
            "2020    26129\n",
            "2021    30234\n",
            "2022    21109\n",
            "2023    15409\n",
            "2024    17077\n",
            "2025    16833\n"
          ]
        }
      ],
      "source": [
        "# Date formats to avoid parsing warnings\n",
        "KINGCO_DATE_FORMAT = '%Y-%m-%d'\n",
        "SPD_DATE_FORMAT = '%m/%d/%Y %I:%M:%S %p'\n",
        "\n",
        "# Load sales data - read only date column for efficiency (sales_temp is a temporary dataframe used only in this cell for the year analysis)\n",
        "sales_temp = pd.read_csv('kingco_sales.csv', usecols=['sale_date'])\n",
        "sales_temp['sale_date'] = pd.to_datetime(sales_temp['sale_date'], format=KINGCO_DATE_FORMAT, errors='coerce')\n",
        "sales_temp['year'] = sales_temp['sale_date'].dt.year\n",
        "sales_years = np.unique(sales_temp['year'].dropna()).astype(int).tolist()\n",
        "\n",
        "# Count records per year\n",
        "counts_per_year = sales_temp['year'].value_counts().sort_index()\n",
        "\n",
        "print('kingco_sales.csv (sales_df)')\n",
        "print(f'Unique years (sale_date): {sales_years}')\n",
        "print(f'Year range: {min(sales_years)} - {max(sales_years)}')\n",
        "print(f'\\nRecords per year:')\n",
        "print(counts_per_year.to_string())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "SPD_Crime_Data__2008-Present.csv (crimes_df)\n",
            "Unique years (Offense Date): [1900, 1908, 1915, 1920, 1929, 1934, 1951, 1953, 1957, 1960, 1964, 1966, 1968, 1973, 1974, 1975, 1976, 1977, 1978, 1979, 1980, 1981, 1982, 1983, 1984, 1985, 1986, 1987, 1988, 1989, 1990, 1991, 1992, 1993, 1994, 1995, 1996, 1997, 1998, 1999, 2000, 2001, 2002, 2003, 2004, 2005, 2006, 2007, 2008, 2009, 2010, 2011, 2012, 2013, 2014, 2015, 2016, 2017, 2018, 2019, 2020, 2021, 2022, 2023, 2024, 2025]\n",
            "Year range: 1900 - 2025\n",
            "\n",
            "Records per year:\n",
            "year\n",
            "1900        5\n",
            "1908        1\n",
            "1915        1\n",
            "1920        1\n",
            "1929        1\n",
            "1934        1\n",
            "1951        1\n",
            "1953        1\n",
            "1957        1\n",
            "1960        1\n",
            "1964        4\n",
            "1966        2\n",
            "1968        1\n",
            "1973        1\n",
            "1974        3\n",
            "1975        3\n",
            "1976        5\n",
            "1977        3\n",
            "1978        1\n",
            "1979        3\n",
            "1980        7\n",
            "1981        3\n",
            "1982        1\n",
            "1983        4\n",
            "1984        2\n",
            "1985        3\n",
            "1986        1\n",
            "1987        5\n",
            "1988        3\n",
            "1989        4\n",
            "1990        6\n",
            "1991       19\n",
            "1992        4\n",
            "1993       11\n",
            "1994       10\n",
            "1995       15\n",
            "1996       10\n",
            "1997       20\n",
            "1998       40\n",
            "1999       30\n",
            "2000       98\n",
            "2001      118\n",
            "2002       56\n",
            "2003       83\n",
            "2004      132\n",
            "2005      171\n",
            "2006      337\n",
            "2007     1547\n",
            "2008    86060\n",
            "2009    84671\n",
            "2010    81928\n",
            "2011    76396\n",
            "2012    74527\n",
            "2013    79563\n",
            "2014    84166\n",
            "2015    83719\n",
            "2016    86919\n",
            "2017    89647\n",
            "2018    92514\n",
            "2019    84078\n",
            "2020    86890\n",
            "2021    81473\n",
            "2022    87277\n",
            "2023    82531\n",
            "2024    81540\n",
            "2025    27675\n"
          ]
        }
      ],
      "source": [
        "# Load crimes data - use chunks for large file\n",
        "crimes_years_list = []\n",
        "for chunk in pd.read_csv('SPD_Crime_Data__2008-Present.csv', chunksize=100000, usecols=['Offense Date'], low_memory=False):\n",
        "    chunk['Offense Date'] = pd.to_datetime(chunk['Offense Date'], format=SPD_DATE_FORMAT, errors='coerce')\n",
        "    chunk['year'] = chunk['Offense Date'].dt.year\n",
        "    crimes_years_list.append(chunk['year'])\n",
        "\n",
        "crimes_years_series = pd.concat(crimes_years_list)\n",
        "counts_per_year_crimes = crimes_years_series.value_counts().sort_index()\n",
        "crimes_years = np.unique(crimes_years_series.dropna()).astype(int).tolist()\n",
        "\n",
        "print('SPD_Crime_Data__2008-Present.csv (crimes_df)')\n",
        "print(f'Unique years (Offense Date): {crimes_years}')\n",
        "print(f'Year range: {min(crimes_years)} - {max(crimes_years)}')\n",
        "print(f'\\nRecords per year:')\n",
        "print(counts_per_year_crimes.to_string())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Filter Data to Matching Years\n",
        "\n",
        "Keep only records from 2021 onwards that appear in both datasets."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Matching years (from 2021): [np.int64(2021), np.int64(2022), np.int64(2023), np.int64(2024), np.int64(2025)]\n",
            "\n",
            "sales_df: 90,167 rows\n",
            "crimes_df: 360,445 rows\n",
            "END_DATE (min max - 1 day): 2025-05-24 00:00:00\n"
          ]
        }
      ],
      "source": [
        "# Find years that appear in both datasets, from 2021 onwards\n",
        "START_YEAR = 2021\n",
        "matching_years = [y for y in np.intersect1d(sales_years, crimes_years) if y >= START_YEAR]\n",
        "print(f'Matching years (from {START_YEAR}): {matching_years}')\n",
        "\n",
        "# Filter sales data to matching years only\n",
        "sales_raw = pd.read_csv('kingco_sales.csv')\n",
        "sales_raw['sale_date'] = pd.to_datetime(sales_raw['sale_date'], format=KINGCO_DATE_FORMAT, errors='coerce')\n",
        "sales_raw['year'] = sales_raw['sale_date'].dt.year\n",
        "sales_df = sales_raw[sales_raw['year'].isin(matching_years)].copy()\n",
        "\n",
        "# Filter crimes data to matching years only (load in chunks)\n",
        "crimes_chunks = []\n",
        "for chunk in pd.read_csv('SPD_Crime_Data__2008-Present.csv', chunksize=100000, low_memory=False):\n",
        "    chunk['Offense Date'] = pd.to_datetime(chunk['Offense Date'], format=SPD_DATE_FORMAT, errors='coerce')\n",
        "    chunk['year'] = chunk['Offense Date'].dt.year\n",
        "    chunk_filtered = chunk[chunk['year'].isin(matching_years)]\n",
        "    crimes_chunks.append(chunk_filtered)\n",
        "\n",
        "crimes_df = pd.concat(crimes_chunks, ignore_index=True)\n",
        "\n",
        "print(f'\\nsales_df: {len(sales_df):,} rows')\n",
        "print(f'crimes_df: {len(crimes_df):,} rows')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Filter to Seattle City Limits (Point-in-Polygon)\n",
        "\n",
        "Use official Seattle boundary (ArcGIS Open Data) with Point-in-Polygon for precise geographic filtering. Convex hull of boundary lines creates the polygon (lines don't form closed loops)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "sales_df (Seattle only, PIP): 22,803 rows\n",
            "crimes_df: 360,445 rows\n",
            "Max crime date: 2025-05-23 23:57:00\n",
            "Max sales date (Seattle): 2025-05-24 00:00:00\n"
          ]
        }
      ],
      "source": [
        "import geopandas as gpd\n",
        "from shapely.geometry import Point\n",
        "from shapely.ops import unary_union\n",
        "\n",
        "# Load Seattle city limits (official boundary from ArcGIS Open Data)\n",
        "# Source: https://opendata.arcgis.com/datasets/c5f3575dd7d545ada27064c74ac74f52\n",
        "boundary_gdf = gpd.read_file('seattle_city_limits.geojson')\n",
        "\n",
        "# Extract line segments (boundary is MultiLineString - lines don't form closed loops)\n",
        "# Use convex hull to create polygon for Point-in-Polygon\n",
        "all_lines = []\n",
        "for geom in boundary_gdf.geometry:\n",
        "    if geom.geom_type == 'MultiLineString':\n",
        "        for line in geom.geoms:\n",
        "            all_lines.append(line)\n",
        "    elif geom.geom_type == 'LineString':\n",
        "        all_lines.append(geom)\n",
        "\n",
        "lines_union = unary_union(all_lines)\n",
        "seattle_boundary = lines_union.convex_hull  # Polygon from boundary envelope\n",
        "\n",
        "# Point-in-Polygon: keep only properties within Seattle boundary\n",
        "sales_df['geometry'] = sales_df.apply(lambda r: Point(r['longitude'], r['latitude']), axis=1)\n",
        "sales_gdf = gpd.GeoDataFrame(sales_df, geometry='geometry', crs='EPSG:4326')\n",
        "in_seattle = sales_gdf.geometry.within(seattle_boundary)\n",
        "sales_df = sales_df[in_seattle].drop(columns=['geometry']).reset_index(drop=True)\n",
        "\n",
        "# crimes_df is already Seattle-only (SPD jurisdiction)\n",
        "print(f'sales_df (Seattle only, PIP): {len(sales_df):,} rows')\n",
        "print(f'crimes_df: {len(crimes_df):,} rows')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Spatial Join: Properties + Crime Counts\n",
        "\n",
        "Join properties with crime data by counting crimes within a radius of each sale location (same year)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Check 2025 matching months/days\n",
        "\n",
        "Ensure overlapping date coverage for Seattle data: use the earlier of the two max dates (crimes vs sales) minus 1 day as cutoff. Reproducible—no hardcoded dates."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Dynamic end date: min of both max dates minus 1 day\n",
        "max_crime_date = crimes_df['Offense Date'].max()\n",
        "max_sales_date = sales_df['sale_date'].max()\n",
        "END_DATE = (min(max_crime_date, max_sales_date) - pd.Timedelta(days=1)).normalize()\n",
        "sales_df = sales_df[sales_df['sale_date'] <= END_DATE].copy()\n",
        "crimes_df = crimes_df[crimes_df['Offense Date'] <= END_DATE].copy()\n",
        "\n",
        "print(f'Max crime date (before cutoff): {max_crime_date}')\n",
        "print(f'Max sales date (Seattle, before cutoff): {max_sales_date}')\n",
        "print(f'END_DATE (min - 1 day): {END_DATE}')\n",
        "print(f'\\nsales_df: {len(sales_df):,} rows')\n",
        "print(f'crimes_df: {len(crimes_df):,} rows')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed 25,414 / 25,414 properties...\n",
            "\n",
            "df_joined: 25,414 rows\n",
            "Crime count stats: min=0, max=5405, mean=594.2\n"
          ]
        }
      ],
      "source": [
        "from scipy.spatial import cKDTree\n",
        "\n",
        "# Filter valid coordinates (crimes_df uses -1.0 for missing; sales_df may have NaN)\n",
        "sales_df = sales_df.dropna(subset=['latitude', 'longitude'])\n",
        "RADIUS_KM = 1.0  # crimes within 1 km of property\n",
        "# At Seattle latitude (~47°): 1° lat ≈ 111 km, 1° long ≈ 76 km\n",
        "# 1 km ≈ 0.009° lat, 0.013° long - use 0.01 as approx for both\n",
        "radius_deg = RADIUS_KM / 111\n",
        "\n",
        "# Prepare crime data - valid coords only\n",
        "crimes_df['Latitude'] = pd.to_numeric(crimes_df['Latitude'], errors='coerce')\n",
        "crimes_df['Longitude'] = pd.to_numeric(crimes_df['Longitude'], errors='coerce')\n",
        "crimes_valid = crimes_df[\n",
        "    (crimes_df['Latitude'] > 40) & (crimes_df['Latitude'] < 50) &\n",
        "    (crimes_df['Longitude'] < -100) & (crimes_df['Longitude'] > -125)\n",
        "].copy()\n",
        "crime_coords = crimes_valid[['Latitude', 'Longitude']].values\n",
        "crime_years = crimes_valid['year'].values\n",
        "\n",
        "# Build spatial index on crimes\n",
        "crime_tree = cKDTree(crime_coords)\n",
        "\n",
        "# Process in batches - vectorized query for speed\n",
        "BATCH_SIZE = 50000\n",
        "crime_counts = []\n",
        "for i in range(0, len(sales_df), BATCH_SIZE):\n",
        "    batch = sales_df.iloc[i:i+BATCH_SIZE]\n",
        "    coords = batch[['latitude', 'longitude']].values\n",
        "    years = batch['year'].values\n",
        "    all_indices = crime_tree.query_ball_point(coords, r=radius_deg)\n",
        "    counts = [sum(1 for idx in inds if crime_years[idx] == years[j]) for j, inds in enumerate(all_indices)]\n",
        "    crime_counts.extend(counts)\n",
        "    print(f'Processed {min(i+BATCH_SIZE, len(sales_df)):,} / {len(sales_df):,} properties...')\n",
        "\n",
        "sales_df['crime_count_1km'] = crime_counts\n",
        "\n",
        "# Create joined df (sales with crime feature)\n",
        "df_joined = sales_df.copy()\n",
        "print(f'\\ndf_joined: {len(df_joined):,} rows')\n",
        "print(f'Crime count stats: min={df_joined[\"crime_count_1km\"].min()}, max={df_joined[\"crime_count_1km\"].max()}, mean={df_joined[\"crime_count_1km\"].mean():.1f}')"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
